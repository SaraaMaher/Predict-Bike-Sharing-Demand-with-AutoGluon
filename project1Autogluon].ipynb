{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraaMaher/Predict-Bike-Sharing-Demand-with-AutoGluon/blob/main/project1Autogluon%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmaiV2TsZLf"
      },
      "source": [
        "# Predict Bike Sharing Demand with AutoGluon Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDgAwKZLsZLl"
      },
      "source": [
        "## Project: Predict Bike Sharing Demand with AutoGluon\n",
        "This notebook is a template with each step that you need to complete for the project.\n",
        "\n",
        "Please fill in your code where there are explicit `?` markers in the notebook. You are welcome to add more cells and code as you see fit.\n",
        "\n",
        "Once you have completed all the code implementations, please export your notebook as a HTML file so the reviews can view your code. Make sure you have all outputs correctly outputted.\n",
        "\n",
        "`File-> Export Notebook As... -> Export Notebook as HTML`\n",
        "\n",
        "There is a writeup to complete as well after all code implememtation is done. Please answer all questions and attach the necessary tables and charts. You can complete the writeup in either markdown or PDF.\n",
        "\n",
        "Completing the code template and writeup template will cover all of the rubric points for this project.\n",
        "\n",
        "The rubric contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this notebook and also discuss the results in the writeup file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7f6f4BxsZLm"
      },
      "source": [
        "## Step 1: Create an account with Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCtKz83MsZLn"
      },
      "source": [
        "### Create Kaggle Account and download API key\n",
        "Below is example of steps to get the API username and key. Each student will have their own username and key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azgNOzPvsZLn"
      },
      "source": [
        "1. Open account settings.\n",
        "![kaggle1.png](attachment:kaggle1.png)\n",
        "![kaggle2.png](attachment:kaggle2.png)\n",
        "2. Scroll down to API and click Create New API Token.\n",
        "![kaggle3.png](attachment:kaggle3.png)\n",
        "![kaggle4.png](attachment:kaggle4.png)\n",
        "3. Open up `kaggle.json` and use the username and key.\n",
        "![kaggle5.png](attachment:kaggle5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz6HhqtgsZLo"
      },
      "source": [
        "## Step 2: Download the Kaggle dataset using the kaggle python library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pabX1nqSsZLp"
      },
      "source": [
        "### Open up Sagemaker Studio and use starter template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftKACalmsZLq"
      },
      "source": [
        "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
        "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9Q8LqvsZLr"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R7MCk10EsZLs",
        "outputId": "0ac435b1-16bf-4149-a86f-5fc3f39983d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 28.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.2.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-65.2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet<2.0.0\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bokeh==2.0.1\n",
            "  Downloading bokeh-2.0.1.tar.gz (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (7.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (21.3)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (5.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.0.1) (4.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh==2.0.1) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
            "Building wheels for collected packages: bokeh\n",
            "  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bokeh: filename=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=f28fdfedee41bccbb3e1798463fb572df8edf44de78438c3536ed96f5505eff0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/9e/ac/f24f30e119df73511fde9af8aa747217ac8824e662037ba9a8\n",
            "Successfully built bokeh\n",
            "Installing collected packages: graphviz, mxnet, bokeh\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 2.3.3\n",
            "    Uninstalling bokeh-2.3.3:\n",
            "      Successfully uninstalled bokeh-2.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires bokeh<2.4.0,>=2.3.0, but you have bokeh 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autogluon\n",
            "  Downloading autogluon-0.5.2-py3-none-any.whl (9.6 kB)\n",
            "Collecting autogluon.features==0.5.2\n",
            "  Downloading autogluon.features-0.5.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m140.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.text==0.5.2\n",
            "  Downloading autogluon.text-0.5.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m168.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.multimodal==0.5.2\n",
            "  Downloading autogluon.multimodal-0.5.2-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m190.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.timeseries[all]==0.5.2\n",
            "  Downloading autogluon.timeseries-0.5.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.vision==0.5.2\n",
            "  Downloading autogluon.vision-0.5.2-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m145.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.5.2\n",
            "  Downloading autogluon.tabular-0.5.2-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m197.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.core[all]==0.5.2\n",
            "  Downloading autogluon.core-0.5.2-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.4/210.4 kB\u001b[0m \u001b[31m186.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distributed<=2021.11.2,>=2021.09.1\n",
            "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.57-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m189.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.5.2->autogluon) (4.64.0)\n",
            "Collecting dask<=2021.11.2,>=2021.09.1\n",
            "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.23,>=1.21 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.5.2->autogluon) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.5.2->autogluon) (2.23.0)\n",
            "Requirement already satisfied: pandas!=1.4.0,<1.5,>=1.2.5 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.5.2->autogluon) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn<1.1,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.5.2->autogluon) (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.5.2->autogluon) (3.2.2)\n",
            "Collecting autogluon.common==0.5.2\n",
            "  Downloading autogluon.common-0.5.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: scipy<1.8.0,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.5.2->autogluon) (1.7.3)\n",
            "Collecting hyperopt<0.2.8,>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m156.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray[tune]<1.14,>=1.13\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 MB\u001b[0m \u001b[31m207.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil<6,>=5.7.3\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 kB\u001b[0m \u001b[31m225.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<4.21.0,>=4.18.0\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m221.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image<0.20.0,>=0.19.1\n",
            "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m206.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning<1.7.0,>=1.6.0\n",
            "  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 kB\u001b[0m \u001b[31m222.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nptyping<1.5.0,>=1.4.4\n",
            "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
            "Collecting torchmetrics<0.8.0,>=0.7.2\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.2/398.2 kB\u001b[0m \u001b[31m232.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<=1.1.10,>=1.1.10\n",
            "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.8/410.8 kB\u001b[0m \u001b[31m221.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale<=0.4.6,>=0.4.5\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m225.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf<=3.18.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.multimodal==0.5.2->autogluon) (3.17.3)\n",
            "Requirement already satisfied: torch<1.13,>=1.9 in /usr/local/lib/python3.7/dist-packages (from autogluon.multimodal==0.5.2->autogluon) (1.12.1+cu113)\n",
            "Collecting omegaconf<2.2.0,>=2.1.1\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m169.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<9.1.0,>=9.0.1\n",
            "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m231.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.14.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.multimodal==0.5.2->autogluon) (0.13.1+cu113)\n",
            "Requirement already satisfied: torchtext<0.14.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.multimodal==0.5.2->autogluon) (0.13.1)\n",
            "Collecting timm<0.6.0\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m239.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<5.3.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.multimodal==0.5.2->autogluon) (5.2.1)\n",
            "Collecting sentencepiece<0.2.0,>=0.1.95\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m241.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-metric-learning<1.4.0,>=1.3.0\n",
            "  Downloading pytorch_metric_learning-1.3.2-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m197.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.7/dist-packages (from autogluon.multimodal==0.5.2->autogluon) (3.7)\n",
            "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.5.2->autogluon) (2.6.3)\n",
            "Collecting catboost<1.1,>=1.0\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m204.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost<1.5,>=1.4\n",
            "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m159.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.5.2->autogluon) (2.7.9)\n",
            "Collecting lightgbm<3.4,>=3.3\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m237.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20220208\n",
            "  Downloading autogluon_contrib_nlp-0.0.1b20220208-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gluonts<0.10.0,>=0.8.0\n",
            "  Downloading gluonts-0.9.8-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m205.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil<6,>=5.7.3\n",
            "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m201.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sktime~=0.11.4\n",
            "  Downloading sktime-0.11.4-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m205.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima~=1.8.2\n",
            "  Downloading pmdarima-1.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m243.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tbats~=1.1\n",
            "  Downloading tbats-1.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m125.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gluoncv<0.10.6,>=0.10.5\n",
            "  Downloading gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8\n",
            "  Downloading flake8-5.0.4-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m152.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contextvars\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacremoses>=0.0.38\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m230.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (2022.6.2)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (6.0.1)\n",
            "Collecting tokenizers>=0.9.4\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m201.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m247.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (0.8.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.5.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (0.12.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2022.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (21.3)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (7.1.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.11.3)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (5.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (65.2.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.2.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.4.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.3)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.5.21)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (22.2.2)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.4.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.0.7)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.2->autogluon) (4.6.0.66)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: holidays>=0.9 in /usr/local/lib/python3.7/dist-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.14.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.7/dist-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (4.1.1)\n",
            "Requirement already satisfied: pydantic~=1.1 in /usr/local/lib/python3.7/dist-packages (from gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (1.9.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.5.2->autogluon) (0.16.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m228.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.5.2->autogluon) (0.37.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core[all]==0.5.2->autogluon) (3.0.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.5.2->autogluon) (1.1.0)\n",
            "Collecting typish>=1.7.0\n",
            "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m175.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.4.0,<1.5,>=1.2.5->autogluon.core[all]==0.5.2->autogluon) (2022.2.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (1.24.3)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.29.32)\n",
            "Requirement already satisfied: statsmodels!=0.12.0,>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.12.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (2.8.0)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m216.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (22.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.2.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (4.3.3)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.16.3-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m173.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (3.8.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (1.3.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.8.10)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core[all]==0.5.2->autogluon) (2.10)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core[all]==0.5.2->autogluon) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.7/dist-packages (from sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (0.56.0)\n",
            "Collecting deprecated>=1.2.13\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m205.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.21.0,>=4.18.0->autogluon.multimodal==0.5.2->autogluon) (4.12.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.28.0,>=1.27.57\n",
            "  Downloading botocore-1.27.57-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m198.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m167.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m190.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.13->sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (1.14.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (3.8.1)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (2.4.0)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.2.1)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (2.2.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53->sktime~=0.11.4->autogluon.timeseries[all]==0.5.2->autogluon) (0.39.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.0.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (8.1.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.3.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.4.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.4.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (3.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.6.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (1.0.8)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels!=0.12.0,>=0.11->pmdarima~=1.8.2->autogluon.timeseries[all]==0.5.2->autogluon) (0.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.8.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.0.1)\n",
            "Collecting immutables>=0.9\n",
            "  Downloading immutables-0.18-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 kB\u001b[0m \u001b[31m200.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle<2.10.0,>=2.9.0\n",
            "  Downloading pycodestyle-2.9.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m130.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting pyflakes<2.6.0,>=2.5.0\n",
            "  Downloading pyflakes-2.5.0-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<4.21.0,>=4.18.0->autogluon.multimodal==0.5.2->autogluon) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.0.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]<1.14,>=1.13->autogluon.core[all]==0.5.2->autogluon) (5.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.2->autogluon) (8.0.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.5.2->autogluon) (4.9.1)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.16.2-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m213.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.5-py2.py3-none-any.whl (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.0/467.0 kB\u001b[0m \u001b[31m220.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.9->gluonts<0.10.0,>=0.8.0->autogluon.timeseries[all]==0.5.2->autogluon) (0.5.11)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (1.3.1)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m178.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m180.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m188.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m176.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.5.2->autogluon) (0.7.8)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (2.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.2->autogluon) (1.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.6.0->autogluon.multimodal==0.5.2->autogluon) (3.2.0)\n",
            "Building wheels for collected packages: fairscale, antlr4-python3-runtime, sacremoses, contextvars\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307225 sha256=19e784fee0b4179b1f0051bce5bb753620b4550a1a41d5566622dcec506c1493\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_urr6nlc/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=4410366c390143ef7ef35779806f6f2adb8e3967b808d6f97a989e56614e8f35\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_urr6nlc/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=411195b89a47587dbc5e5fd17f805a4d20a05ed3215aae86b4dffb329fcc92b7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_urr6nlc/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7664 sha256=0a8e3ec454d71f9e4aaaf76f6d843798743e0bfd94e7e168bfda907ecdccb7a7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_urr6nlc/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
            "Successfully built fairscale antlr4-python3-runtime sacremoses contextvars\n",
            "Installing collected packages: typish, tokenizers, sentencepiece, py4j, distlib, antlr4-python3-runtime, yacs, urllib3, sacremoses, pyflakes, pyDeprecate, pycodestyle, psutil, portalocker, platformdirs, Pillow, omegaconf, nptyping, mccabe, jmespath, importlib-metadata, immutables, grpcio, deprecated, colorama, autocfg, xgboost, virtualenv, torchmetrics, tensorboardX, sacrebleu, markdown, hyperopt, flake8, fairscale, dask, contextvars, botocore, scikit-image, s3transfer, ray, nlpaug, lightgbm, huggingface-hub, gluonts, gluoncv, distributed, catboost, autogluon-contrib-nlp, transformers, timm, sktime, pytorch-metric-learning, pmdarima, boto3, tbats, autogluon.common, pytorch-lightning, autogluon.features, autogluon.core, autogluon.vision, autogluon.timeseries, autogluon.tabular, autogluon.multimodal, autogluon.text, autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.12.0\n",
            "    Uninstalling importlib-metadata-4.12.0:\n",
            "      Successfully uninstalled importlib-metadata-4.12.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.4.1\n",
            "    Uninstalling Markdown-3.4.1:\n",
            "      Successfully uninstalled Markdown-3.4.1\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.2.0\n",
            "    Uninstalling dask-2022.2.0:\n",
            "      Successfully uninstalled dask-2022.2.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.2.0\n",
            "    Uninstalling distributed-2022.2.0:\n",
            "      Successfully uninstalled distributed-2022.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires bokeh<2.4.0,>=2.3.0, but you have bokeh 2.0.1 which is incompatible.\n",
            "gym 0.25.1 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.0.1 antlr4-python3-runtime-4.8 autocfg-0.0.8 autogluon-0.5.2 autogluon-contrib-nlp-0.0.1b20220208 autogluon.common-0.5.2 autogluon.core-0.5.2 autogluon.features-0.5.2 autogluon.multimodal-0.5.2 autogluon.tabular-0.5.2 autogluon.text-0.5.2 autogluon.timeseries-0.5.2 autogluon.vision-0.5.2 boto3-1.24.57 botocore-1.27.57 catboost-1.0.6 colorama-0.4.5 contextvars-2.4 dask-2021.11.2 deprecated-1.2.13 distlib-0.3.5 distributed-2021.11.2 fairscale-0.4.6 flake8-5.0.4 gluoncv-0.10.5.post0 gluonts-0.9.8 grpcio-1.43.0 huggingface-hub-0.8.1 hyperopt-0.2.7 immutables-0.18 importlib-metadata-4.2.0 jmespath-1.0.1 lightgbm-3.3.2 markdown-3.3.4 mccabe-0.7.0 nlpaug-1.1.10 nptyping-1.4.4 omegaconf-2.1.2 platformdirs-2.5.2 pmdarima-1.8.5 portalocker-2.5.1 psutil-5.8.0 py4j-0.10.9.7 pyDeprecate-0.3.2 pycodestyle-2.9.1 pyflakes-2.5.0 pytorch-lightning-1.6.5 pytorch-metric-learning-1.3.2 ray-1.13.0 s3transfer-0.6.0 sacrebleu-2.2.0 sacremoses-0.0.53 scikit-image-0.19.3 sentencepiece-0.1.95 sktime-0.11.4 tbats-1.1.0 tensorboardX-2.5.1 timm-0.5.4 tokenizers-0.12.1 torchmetrics-0.7.3 transformers-4.20.1 typish-1.9.3 urllib3-1.25.11 virtualenv-20.16.2 xgboost-1.4.2 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U setuptools wheel\n",
        "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
        "!pip install autogluon --no-cache-dir\n",
        "# Without --no-cache-dir, smaller aws instances may have trouble installing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfNKZjV-sZLu"
      },
      "source": [
        "### Setup Kaggle API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Et6Ei_M7sZLv"
      },
      "outputs": [],
      "source": [
        "# create the .kaggle directory and an empty kaggle.json file\n",
        "!mkdir -p /root/.kaggle\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QUN-nk6gsZLw"
      },
      "outputs": [],
      "source": [
        "# Fill in your user name and key from creating the kaggle account and API token file\n",
        "import json\n",
        "kaggle_username = \"saraahmedmaher\"\n",
        "kaggle_key = \"fb55d976fc2ab4c8123409c48d2dd11f\"\n",
        "\n",
        "# Save API token the kaggle.json file\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bONPEDGtsZLx"
      },
      "source": [
        "### Download and explore dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0v9XetAsZLx"
      },
      "source": [
        "### Go to the bike sharing demand competition and agree to the terms\n",
        "![kaggle6.png](attachment:kaggle6.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r3pkCC8zsZLx",
        "outputId": "33c360b6-e7a8-4948-ca9a-c77c435bc763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bike-sharing-demand.zip to /content\n",
            "\r  0% 0.00/189k [00:00<?, ?B/s]\n",
            "\r100% 189k/189k [00:00<00:00, 58.5MB/s]\n",
            "Archive:  bike-sharing-demand.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "# Download the dataset, it will be in a .zip file so you'll need to unzip it as well.\n",
        "!kaggle competitions download -c bike-sharing-demand\n",
        "# If you already downloaded it you can use the -o command to overwrite the file\n",
        "!unzip -o bike-sharing-demand.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yfOFnanAsZLy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VIx6KcHssZLy"
      },
      "outputs": [],
      "source": [
        "# Create the train dataset in pandas by reading the csv\n",
        "# Set the parsing of the datetime column so you can use some of the `dt` features in pandas later\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "train['datetime']=pd.to_datetime(train.loc[:, \"datetime\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "qX0qaZlFuH_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9acbbb09-b399-4ead-8a29-c011ca062d26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
              "0 2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
              "1 2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
              "2 2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
              "3 2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
              "4 2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
              "\n",
              "   humidity  windspeed  casual  registered  count  \n",
              "0        81        0.0       3          13     16  \n",
              "1        80        0.0       8          32     40  \n",
              "2        80        0.0       5          27     32  \n",
              "3        75        0.0       3          10     13  \n",
              "4        75        0.0       0           1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0836c1e4-8c1c-42d5-9ec8-79d7e9dca041\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0836c1e4-8c1c-42d5-9ec8-79d7e9dca041')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0836c1e4-8c1c-42d5-9ec8-79d7e9dca041 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0836c1e4-8c1c-42d5-9ec8-79d7e9dca041');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9betxo-GsZLy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "b06acbff-cc3b-4918-cfd6-93d64c55e6fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             season       holiday    workingday       weather         temp  \\\n",
              "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
              "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
              "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
              "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
              "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
              "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
              "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
              "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
              "\n",
              "              atemp      humidity     windspeed        casual    registered  \\\n",
              "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
              "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
              "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
              "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
              "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
              "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
              "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
              "\n",
              "              count  \n",
              "count  10886.000000  \n",
              "mean     191.574132  \n",
              "std      181.144454  \n",
              "min        1.000000  \n",
              "25%       42.000000  \n",
              "50%      145.000000  \n",
              "75%      284.000000  \n",
              "max      977.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02e07e41-46eb-4e37-9a00-f9e430f08b6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.00000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "      <td>10886.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.506614</td>\n",
              "      <td>0.028569</td>\n",
              "      <td>0.680875</td>\n",
              "      <td>1.418427</td>\n",
              "      <td>20.23086</td>\n",
              "      <td>23.655084</td>\n",
              "      <td>61.886460</td>\n",
              "      <td>12.799395</td>\n",
              "      <td>36.021955</td>\n",
              "      <td>155.552177</td>\n",
              "      <td>191.574132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.116174</td>\n",
              "      <td>0.166599</td>\n",
              "      <td>0.466159</td>\n",
              "      <td>0.633839</td>\n",
              "      <td>7.79159</td>\n",
              "      <td>8.474601</td>\n",
              "      <td>19.245033</td>\n",
              "      <td>8.164537</td>\n",
              "      <td>49.960477</td>\n",
              "      <td>151.039033</td>\n",
              "      <td>181.144454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.82000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.94000</td>\n",
              "      <td>16.665000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>7.001500</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.50000</td>\n",
              "      <td>24.240000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>12.998000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>145.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>26.24000</td>\n",
              "      <td>31.060000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>16.997900</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>222.000000</td>\n",
              "      <td>284.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>41.00000</td>\n",
              "      <td>45.455000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>56.996900</td>\n",
              "      <td>367.000000</td>\n",
              "      <td>886.000000</td>\n",
              "      <td>977.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02e07e41-46eb-4e37-9a00-f9e430f08b6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02e07e41-46eb-4e37-9a00-f9e430f08b6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02e07e41-46eb-4e37-9a00-f9e430f08b6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Simple output of the train dataset to view some of the min/max/varition of the dataset features.\n",
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6wtBkvCJsZLz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c3e20cf6-2fb1-45bd-f9ae-089576e09120"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
              "0 2011-01-20 00:00:00       1        0           1        1  10.66  11.365   \n",
              "1 2011-01-20 01:00:00       1        0           1        1  10.66  13.635   \n",
              "2 2011-01-20 02:00:00       1        0           1        1  10.66  13.635   \n",
              "3 2011-01-20 03:00:00       1        0           1        1  10.66  12.880   \n",
              "4 2011-01-20 04:00:00       1        0           1        1  10.66  12.880   \n",
              "\n",
              "   humidity  windspeed  \n",
              "0        56    26.0027  \n",
              "1        56     0.0000  \n",
              "2        56     0.0000  \n",
              "3        56    11.0014  \n",
              "4        56    11.0014  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5425fcab-ad1d-420b-8e9a-5f46a3606af5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>11.365</td>\n",
              "      <td>56</td>\n",
              "      <td>26.0027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>13.635</td>\n",
              "      <td>56</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.66</td>\n",
              "      <td>12.880</td>\n",
              "      <td>56</td>\n",
              "      <td>11.0014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5425fcab-ad1d-420b-8e9a-5f46a3606af5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5425fcab-ad1d-420b-8e9a-5f46a3606af5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5425fcab-ad1d-420b-8e9a-5f46a3606af5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "test['datetime']=pd.to_datetime(test.loc[:, \"datetime\"])\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kpxE0kYxsZLz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "57cd36cb-6f3b-4a7d-9614-6d43367f5cda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  count\n",
              "0 2011-01-20 00:00:00      0\n",
              "1 2011-01-20 01:00:00      0\n",
              "2 2011-01-20 02:00:00      0\n",
              "3 2011-01-20 03:00:00      0\n",
              "4 2011-01-20 04:00:00      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9758cdb-1beb-406c-9044-12f569a9a336\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9758cdb-1beb-406c-9044-12f569a9a336')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9758cdb-1beb-406c-9044-12f569a9a336 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9758cdb-1beb-406c-9044-12f569a9a336');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Same thing as train and test dataset\n",
        "submission = pd.read_csv('/content/sampleSubmission.csv')\n",
        "submission['datetime']=pd.to_datetime(submission.loc[:, \"datetime\"])\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbt5uEvwsZL0"
      },
      "source": [
        "## Step 3: Train a model using AutoGluon’s Tabular Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJsnEU7csZL0"
      },
      "source": [
        "Requirements:\n",
        "* We are prediting `count`, so it is the label we are setting.\n",
        "* Ignore `casual` and `registered` columns as they are also not present in the test dataset. \n",
        "* Use the `root_mean_squared_error` as the metric to use for evaluation.\n",
        "* Set a time limit of 10 minutes (600 seconds).\n",
        "* Use the preset `best_quality` to focus on creating the best model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(columns=['casual']) \n",
        "train = train.drop(columns=['registered']) "
      ],
      "metadata": {
        "id": "glzY5QoED88E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "KQad303MHT4Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e4fae9ac-9358-4c04-de8d-faf1730fbc42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
              "0 2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
              "1 2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
              "2 2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
              "3 2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
              "4 2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
              "\n",
              "   humidity  windspeed  count  \n",
              "0        81        0.0     16  \n",
              "1        80        0.0     40  \n",
              "2        80        0.0     32  \n",
              "3        75        0.0     13  \n",
              "4        75        0.0      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca04adc6-8f76-43be-9f0f-43cfa9028692\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca04adc6-8f76-43be-9f0f-43cfa9028692')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca04adc6-8f76-43be-9f0f-43cfa9028692 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca04adc6-8f76-43be-9f0f-43cfa9028692');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UPbCm0O8sZL0",
        "outputId": "c0233ea2-d8b6-46a2-b327-157be3e1499c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Level 25:autogluon.common.utils.utils:No path specified. Models will be saved in: \"AutogluonModels/ag-20220823_114330/\"\n",
            "INFO:autogluon.tabular.predictor.predictor:Presets specified: ['best_quality']\n",
            "INFO:autogluon.tabular.predictor.predictor:Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "INFO:autogluon.tabular.learner.default_learner:Beginning AutoGluon training ... Time limit = 600s\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon will save models to \"AutogluonModels/ag-20220823_114330/\"\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon Version:  0.5.2\n",
            "INFO:autogluon.tabular.learner.default_learner:Python Version:     3.7.13\n",
            "INFO:autogluon.tabular.learner.default_learner:Operating System:   Linux\n",
            "INFO:autogluon.tabular.learner.default_learner:Train Data Rows:    10886\n",
            "INFO:autogluon.tabular.learner.default_learner:Train Data Columns: 9\n",
            "INFO:autogluon.tabular.learner.default_learner:Label Column: count\n",
            "INFO:autogluon.tabular.learner.default_learner:Preprocessing data ...\n",
            "Level 25:autogluon.core.utils.utils:AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "INFO:autogluon.core.utils.utils:\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
            "Level 25:autogluon.core.utils.utils:\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "INFO:autogluon.tabular.learner.default_learner:Using Feature Generators to preprocess the data ...\n",
            "INFO:autogluon.features.generators.abstract:Fitting AutoMLPipelineFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tAvailable Memory:                    12665.26 MB\n",
            "INFO:autogluon.features.generators.abstract:\tTrain Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)\n",
            "INFO:autogluon.features.generators.abstract:\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "INFO:autogluon.features.generators.abstract:\tStage 1 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting AsTypeFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "INFO:autogluon.features.generators.abstract:\tStage 2 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting FillNaFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tStage 3 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting IdentityFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting DatetimeFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tStage 4 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting DropUniqueFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tTypes of features in original data (raw dtype, special dtypes):\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('datetime', []) : 1 | ['datetime']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', [])      : 5 | ['season', 'holiday', 'workingday', 'weather', 'humidity']\n",
            "INFO:autogluon.features.generators.abstract:\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "INFO:autogluon.features.generators.abstract:\t0.2s = Fit runtime\n",
            "INFO:autogluon.features.generators.abstract:\t9 features in original data used to generate 13 features in processed data.\n",
            "INFO:autogluon.features.generators.abstract:\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "INFO:autogluon.tabular.learner.default_learner:Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "Level 25:autogluon.core.trainer.abstract_trainer:AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "Level 25:autogluon.core.trainer.abstract_trainer:\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "INFO:autogluon.core.trainer.abstract_trainer:AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting 11 L1 models ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.74s of the 599.75s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-101.5462\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.05s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.1s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.44s of the 599.45s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.04s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.11s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.15s of the 599.17s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-131.4609\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t71.91s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t7.63s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L1 ... Training model for up to 315.56s of the 515.57s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-131.0542\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t30.7s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t1.31s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 281.27s of the 481.28s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-116.5443\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t12.14s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.64s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L1 ... Training model for up to 267.46s of the 467.47s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-130.4986\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t191.2s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.14s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 73.19s of the 273.21s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-124.5881\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t5.75s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.61s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 66.05s of the 266.06s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-136.987\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t73.1s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.45s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Completed 1/20 k-fold bagging repeats ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 188.21s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.44s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting 9 L2 models ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 187.74s of the 187.73s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-60.4852\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t51.96s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t3.09s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L2 ... Training model for up to 130.93s of the 130.92s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-54.9852\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t22.55s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.23s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 105.4s of the 105.38s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-53.3871\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t30.21s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.72s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L2 ... Training model for up to 73.76s of the 73.74s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-55.6598\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t64.02s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.07s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 6.7s of the 6.68s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-53.9228\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t11.64s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.7s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Completed 1/20 k-fold bagging repeats ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -7.11s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-52.8377\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.3s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon training complete, total runtime = 607.45s ... Best model: \"WeightedEnsemble_L3\"\n",
            "INFO:autogluon.tabular.predictor.predictor:TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220823_114330/\")\n"
          ]
        }
      ],
      "source": [
        "pre = TabularPredictor(label='count', eval_metric='root_mean_squared_error').fit(\n",
        "    train, presets='best_quality', time_limit=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2VfJbDWsZL1"
      },
      "source": [
        "### Review AutoGluon's training run with ranking of models that did the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PGW1UgAGsZL1",
        "outputId": "0705da82-1782-4b3c-9d51-0158a0576a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3  -52.837731      12.644489  449.593372                0.001071           0.295026            3       True         15\n",
            "1   RandomForestMSE_BAG_L2  -53.387063      11.710557  415.104146                0.720888          30.210819            2       True         12\n",
            "2     ExtraTreesMSE_BAG_L2  -53.922818      11.689698  396.533025                0.700030          11.639698            2       True         14\n",
            "3          LightGBM_BAG_L2  -54.985214      11.222500  407.447829                0.232831          22.554502            2       True         11\n",
            "4          CatBoost_BAG_L2  -55.659814      11.063505  448.912934                0.073837          64.019607            2       True         13\n",
            "5        LightGBMXT_BAG_L2  -60.485222      14.077018  436.856872                3.087350          51.963545            2       True         10\n",
            "6    KNeighborsDist_BAG_L1  -84.125061       0.109832    0.038094                0.109832           0.038094            1       True          2\n",
            "7      WeightedEnsemble_L2  -84.125061       0.110558    0.479765                0.000726           0.441672            2       True          9\n",
            "8    KNeighborsUnif_BAG_L1 -101.546199       0.104156    0.046271                0.104156           0.046271            1       True          1\n",
            "9   RandomForestMSE_BAG_L1 -116.544294       0.635592   12.144099                0.635592          12.144099            1       True          5\n",
            "10    ExtraTreesMSE_BAG_L1 -124.588053       0.605644    5.754841                0.605644           5.754841            1       True          7\n",
            "11         CatBoost_BAG_L1 -130.498580       0.141835  191.203535                0.141835         191.203535            1       True          6\n",
            "12         LightGBM_BAG_L1 -131.054162       1.312093   30.696074                1.312093          30.696074            1       True          4\n",
            "13       LightGBMXT_BAG_L1 -131.460909       7.626704   71.908271                7.626704          71.908271            1       True          3\n",
            "14  NeuralNetFastAI_BAG_L1 -136.986969       0.453814   73.102144                0.453814          73.102144            1       True          8\n",
            "Number of models trained: 15\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_LGB'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
            "('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
            "('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
            "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20220823_114330/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
              "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
              "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
              "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
              "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
              "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
              "  'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF',\n",
              "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
              "  'ExtraTreesMSE_BAG_L2': 'StackerEnsembleModel_XT',\n",
              "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
              " 'model_performance': {'KNeighborsUnif_BAG_L1': -101.54619908446061,\n",
              "  'KNeighborsDist_BAG_L1': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L1': -131.46090891834504,\n",
              "  'LightGBM_BAG_L1': -131.054161598899,\n",
              "  'RandomForestMSE_BAG_L1': -116.54429428704391,\n",
              "  'CatBoost_BAG_L1': -130.49858036848312,\n",
              "  'ExtraTreesMSE_BAG_L1': -124.58805258915959,\n",
              "  'NeuralNetFastAI_BAG_L1': -136.98696917031606,\n",
              "  'WeightedEnsemble_L2': -84.12506123181602,\n",
              "  'LightGBMXT_BAG_L2': -60.4852217147559,\n",
              "  'LightGBM_BAG_L2': -54.985213521259354,\n",
              "  'RandomForestMSE_BAG_L2': -53.38706331007527,\n",
              "  'CatBoost_BAG_L2': -55.65981373468545,\n",
              "  'ExtraTreesMSE_BAG_L2': -53.922817533850086,\n",
              "  'WeightedEnsemble_L3': -52.83773127626372},\n",
              " 'model_best': 'WeightedEnsemble_L3',\n",
              " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/KNeighborsUnif_BAG_L1/',\n",
              "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/KNeighborsDist_BAG_L1/',\n",
              "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/LightGBMXT_BAG_L1/',\n",
              "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/LightGBM_BAG_L1/',\n",
              "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/RandomForestMSE_BAG_L1/',\n",
              "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/CatBoost_BAG_L1/',\n",
              "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/ExtraTreesMSE_BAG_L1/',\n",
              "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20220823_114330/models/NeuralNetFastAI_BAG_L1/',\n",
              "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20220823_114330/models/WeightedEnsemble_L2/',\n",
              "  'LightGBMXT_BAG_L2': 'AutogluonModels/ag-20220823_114330/models/LightGBMXT_BAG_L2/',\n",
              "  'LightGBM_BAG_L2': 'AutogluonModels/ag-20220823_114330/models/LightGBM_BAG_L2/',\n",
              "  'RandomForestMSE_BAG_L2': 'AutogluonModels/ag-20220823_114330/models/RandomForestMSE_BAG_L2/',\n",
              "  'CatBoost_BAG_L2': 'AutogluonModels/ag-20220823_114330/models/CatBoost_BAG_L2/',\n",
              "  'ExtraTreesMSE_BAG_L2': 'AutogluonModels/ag-20220823_114330/models/ExtraTreesMSE_BAG_L2/',\n",
              "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20220823_114330/models/WeightedEnsemble_L3/'},\n",
              " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.04627108573913574,\n",
              "  'KNeighborsDist_BAG_L1': 0.03809356689453125,\n",
              "  'LightGBMXT_BAG_L1': 71.90827059745789,\n",
              "  'LightGBM_BAG_L1': 30.69607377052307,\n",
              "  'RandomForestMSE_BAG_L1': 12.144098997116089,\n",
              "  'CatBoost_BAG_L1': 191.20353484153748,\n",
              "  'ExtraTreesMSE_BAG_L1': 5.754840612411499,\n",
              "  'NeuralNetFastAI_BAG_L1': 73.10214376449585,\n",
              "  'WeightedEnsemble_L2': 0.44167184829711914,\n",
              "  'LightGBMXT_BAG_L2': 51.963545083999634,\n",
              "  'LightGBM_BAG_L2': 22.55450201034546,\n",
              "  'RandomForestMSE_BAG_L2': 30.21081852912903,\n",
              "  'CatBoost_BAG_L2': 64.019606590271,\n",
              "  'ExtraTreesMSE_BAG_L2': 11.639697551727295,\n",
              "  'WeightedEnsemble_L3': 0.2950263023376465},\n",
              " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.104156494140625,\n",
              "  'KNeighborsDist_BAG_L1': 0.10983157157897949,\n",
              "  'LightGBMXT_BAG_L1': 7.62670373916626,\n",
              "  'LightGBM_BAG_L1': 1.3120927810668945,\n",
              "  'RandomForestMSE_BAG_L1': 0.6355917453765869,\n",
              "  'CatBoost_BAG_L1': 0.14183473587036133,\n",
              "  'ExtraTreesMSE_BAG_L1': 0.6056435108184814,\n",
              "  'NeuralNetFastAI_BAG_L1': 0.4538137912750244,\n",
              "  'WeightedEnsemble_L2': 0.0007264614105224609,\n",
              "  'LightGBMXT_BAG_L2': 3.0873498916625977,\n",
              "  'LightGBM_BAG_L2': 0.23283147811889648,\n",
              "  'RandomForestMSE_BAG_L2': 0.7208883762359619,\n",
              "  'CatBoost_BAG_L2': 0.0738365650177002,\n",
              "  'ExtraTreesMSE_BAG_L2': 0.7000298500061035,\n",
              "  'WeightedEnsemble_L3': 0.0010709762573242188},\n",
              " 'num_bag_folds': 8,\n",
              " 'max_stack_level': 3,\n",
              " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'RandomForestMSE_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True},\n",
              "  'ExtraTreesMSE_BAG_L2': {'use_orig_features': True,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True,\n",
              "   'use_child_oof': True},\n",
              "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
              "   'max_base_models': 25,\n",
              "   'max_base_models_per_type': 5,\n",
              "   'save_bag_folds': True}},\n",
              " 'leaderboard':                      model   score_val  pred_time_val    fit_time  \\\n",
              " 0      WeightedEnsemble_L3  -52.837731      12.644489  449.593372   \n",
              " 1   RandomForestMSE_BAG_L2  -53.387063      11.710557  415.104146   \n",
              " 2     ExtraTreesMSE_BAG_L2  -53.922818      11.689698  396.533025   \n",
              " 3          LightGBM_BAG_L2  -54.985214      11.222500  407.447829   \n",
              " 4          CatBoost_BAG_L2  -55.659814      11.063505  448.912934   \n",
              " 5        LightGBMXT_BAG_L2  -60.485222      14.077018  436.856872   \n",
              " 6    KNeighborsDist_BAG_L1  -84.125061       0.109832    0.038094   \n",
              " 7      WeightedEnsemble_L2  -84.125061       0.110558    0.479765   \n",
              " 8    KNeighborsUnif_BAG_L1 -101.546199       0.104156    0.046271   \n",
              " 9   RandomForestMSE_BAG_L1 -116.544294       0.635592   12.144099   \n",
              " 10    ExtraTreesMSE_BAG_L1 -124.588053       0.605644    5.754841   \n",
              " 11         CatBoost_BAG_L1 -130.498580       0.141835  191.203535   \n",
              " 12         LightGBM_BAG_L1 -131.054162       1.312093   30.696074   \n",
              " 13       LightGBMXT_BAG_L1 -131.460909       7.626704   71.908271   \n",
              " 14  NeuralNetFastAI_BAG_L1 -136.986969       0.453814   73.102144   \n",
              " \n",
              "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              " 0                 0.001071           0.295026            3       True   \n",
              " 1                 0.720888          30.210819            2       True   \n",
              " 2                 0.700030          11.639698            2       True   \n",
              " 3                 0.232831          22.554502            2       True   \n",
              " 4                 0.073837          64.019607            2       True   \n",
              " 5                 3.087350          51.963545            2       True   \n",
              " 6                 0.109832           0.038094            1       True   \n",
              " 7                 0.000726           0.441672            2       True   \n",
              " 8                 0.104156           0.046271            1       True   \n",
              " 9                 0.635592          12.144099            1       True   \n",
              " 10                0.605644           5.754841            1       True   \n",
              " 11                0.141835         191.203535            1       True   \n",
              " 12                1.312093          30.696074            1       True   \n",
              " 13                7.626704          71.908271            1       True   \n",
              " 14                0.453814          73.102144            1       True   \n",
              " \n",
              "     fit_order  \n",
              " 0          15  \n",
              " 1          12  \n",
              " 2          14  \n",
              " 3          11  \n",
              " 4          13  \n",
              " 5          10  \n",
              " 6           2  \n",
              " 7           9  \n",
              " 8           1  \n",
              " 9           5  \n",
              " 10          7  \n",
              " 11          6  \n",
              " 12          4  \n",
              " 13          3  \n",
              " 14          8  }"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "pre.fit_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipekDzVlsZL1"
      },
      "source": [
        "### Create predictions from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = pre.evaluate(train)\n"
      ],
      "metadata": {
        "id": "OfZEPenIUCYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1ac94f-bdc9-4c0e-841a-50128447ae42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:autogluon.tabular.learner.abstract_learner:Evaluation: root_mean_squared_error on test data: -71.324543977771\n",
            "INFO:autogluon.tabular.learner.abstract_learner:\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "INFO:autogluon.tabular.learner.abstract_learner:Evaluations on test data:\n",
            "INFO:autogluon.tabular.learner.abstract_learner:{\n",
            "    \"root_mean_squared_error\": -71.324543977771,\n",
            "    \"mean_squared_error\": -5087.190573636989,\n",
            "    \"mean_absolute_error\": -48.8050400136193,\n",
            "    \"r2\": 0.8449514101875084,\n",
            "    \"pearsonr\": 0.945894128054235,\n",
            "    \"median_absolute_error\": -29.145158767700195\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TCudadVrsZL1",
        "outputId": "b736daa1-6f95-44d8-d53e-d6e3587d5c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    22.765511\n",
              "1    41.299957\n",
              "2    45.259937\n",
              "3    48.917870\n",
              "4    51.704922\n",
              "Name: count, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "predictions = pre.predict(test)\n",
        "predictions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGnqSpMysZL1"
      },
      "source": [
        "#### NOTE: Kaggle will reject the submission if we don't set everything to be > 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "JcBc_hlosZL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb342206-9d87-4737-fb0b-b07b3ba552e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6493.000000\n",
              "mean      100.729111\n",
              "std        90.219749\n",
              "min         3.133119\n",
              "25%        20.410442\n",
              "50%        62.568832\n",
              "75%       170.445862\n",
              "max       364.899109\n",
              "Name: count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Describe the `predictions` series to see if there are any negative values\n",
        "predictions.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tvoU3t23sZL2"
      },
      "outputs": [],
      "source": [
        "# How many negative values do we have?\n",
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "fctSP_5nsZL2"
      },
      "outputs": [],
      "source": [
        "# Set them to zero\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmnwzMjKsZL2"
      },
      "source": [
        "### Set predictions to submission dataframe, save, and submit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.head()"
      ],
      "metadata": {
        "id": "t4AQJkRuUZ_b",
        "outputId": "ffec025f-0c96-4009-83e4-f07a185e8c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    22.765511\n",
              "1    41.299957\n",
              "2    45.259937\n",
              "3    48.917870\n",
              "4    51.704922\n",
              "Name: count, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rKFKR4Z3sZL2"
      },
      "outputs": [],
      "source": [
        "submission[\"count\"] = predictions\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z9ZtAa0lsZL3",
        "outputId": "6f6a8cd2-da52-41d7-99ab-7dff478b0815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:00<00:00, 365kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m \"first raw submission\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15WNqojCsZL3"
      },
      "source": [
        "#### View submission via the command line or in the web browser under the competition's page - `My Submissions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UPQ9g-dhsZL3",
        "outputId": "7f09066d-1e35-4ff8-99c2-e7d17f833094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName        date                 description           status    publicScore  privateScore  \n",
            "--------------  -------------------  --------------------  --------  -----------  ------------  \n",
            "submission.csv  2022-08-23 11:54:43  first raw submission  complete  1.80394      1.80394       \n",
            "submission.csv  2022-08-22 16:11:25  first raw submission  complete  1.77783      1.77783       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjER-eF0sZL4"
      },
      "source": [
        "#### Initial score of `?`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm2VEB8YsZL4"
      },
      "source": [
        "## Step 4: Exploratory Data Analysis and Creating an additional feature\n",
        "* Any additional feature will do, but a great suggestion would be to separate out the datetime into hour, day, or month parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jTBVdAifsZL4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "515b10e9-8b74-4125-ae40-b19c8b4c8669"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef6601d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef62e510>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef58af90>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef53e590>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef4efbd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef4ac210>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef4e0890>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef493dd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef493e10>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef44f550>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef3bcfd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ef37c610>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis\n",
        "train.hist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV2szs1Fotw-",
        "outputId": "2b968e7e-ee3d-444a-e819-4e10625b122b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10886 entries, 0 to 10885\n",
            "Data columns (total 10 columns):\n",
            " #   Column      Non-Null Count  Dtype         \n",
            "---  ------      --------------  -----         \n",
            " 0   datetime    10886 non-null  datetime64[ns]\n",
            " 1   season      10886 non-null  int64         \n",
            " 2   holiday     10886 non-null  int64         \n",
            " 3   workingday  10886 non-null  int64         \n",
            " 4   weather     10886 non-null  int64         \n",
            " 5   temp        10886 non-null  float64       \n",
            " 6   atemp       10886 non-null  float64       \n",
            " 7   humidity    10886 non-null  int64         \n",
            " 8   windspeed   10886 non-null  float64       \n",
            " 9   count       10886 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(3), int64(6)\n",
            "memory usage: 850.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Mw73B6LfsZL4"
      },
      "outputs": [],
      "source": [
        "# create a new feature\n",
        "train['year'] = train['datetime'].dt.year\n",
        "\n",
        "#test[?] = ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['month'] = train['datetime'].dt.month\n",
        "train['day'] = train['datetime'].dt.day"
      ],
      "metadata": {
        "id": "DEbMDYu4pdIJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['time'] = train['datetime'].dt.time\n"
      ],
      "metadata": {
        "id": "QIRyO-rCpfoK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(columns=['datetime']) "
      ],
      "metadata": {
        "id": "q2lAmjeXprKG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "kXB2jdwjpJQI",
        "outputId": "bfc511f3-ee25-416c-d266-5854f73b6e8d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   season  holiday  workingday  weather  temp   atemp  humidity  windspeed  \\\n",
              "0       1        0           0        1  9.84  14.395        81        0.0   \n",
              "1       1        0           0        1  9.02  13.635        80        0.0   \n",
              "2       1        0           0        1  9.02  13.635        80        0.0   \n",
              "3       1        0           0        1  9.84  14.395        75        0.0   \n",
              "4       1        0           0        1  9.84  14.395        75        0.0   \n",
              "\n",
              "   count  year  month  day      time  \n",
              "0     16  2011      1    1  00:00:00  \n",
              "1     40  2011      1    1  01:00:00  \n",
              "2     32  2011      1    1  02:00:00  \n",
              "3     13  2011      1    1  03:00:00  \n",
              "4      1  2011      1    1  04:00:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-222fc1a7-8650-42ea-9d7d-9bafda936955\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>count</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>01:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>02:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>03:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>04:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-222fc1a7-8650-42ea-9d7d-9bafda936955')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-222fc1a7-8650-42ea-9d7d-9bafda936955 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-222fc1a7-8650-42ea-9d7d-9bafda936955');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['year'] = test['datetime'].dt.year\n",
        "test['month'] = test['datetime'].dt.month\n",
        "test['day'] = test['datetime'].dt.day\n",
        "test['time'] = test['datetime'].dt.time\n",
        "test = test.drop(columns=['datetime']) \n",
        "test.head()"
      ],
      "metadata": {
        "id": "ynxGiYXVp1f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1mTSD_YsZL5"
      },
      "source": [
        "## Make category types for these so models know they are not just numbers\n",
        "* AutoGluon originally sees these as ints, but in reality they are int representations of a category.\n",
        "* Setting the dtype to category will classify these as categories in AutoGluon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "u5hcZy4FsZL5"
      },
      "outputs": [],
      "source": [
        "train[\"season\"] = train[\"season\"].astype(\"category\")\n",
        "train[\"weather\"] = train[\"weather\"].astype(\"category\")\n",
        "test[\"season\"] = test[\"season\"].astype(\"category\")\n",
        "test[\"weather\"] = test[\"weather\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDL4KTrjsZL5"
      },
      "outputs": [],
      "source": [
        "# View are new feature\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "22eohd5ysKLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8oC99J1tsZL5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "4c7e6508-f1f1-4ce9-fc80-60b5731686a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1efafb650>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1efabc3d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee4610d0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee257a10>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee28afd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee24b650>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee20bc90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee1cd250>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee1cd290>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee183990>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee0fd4d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe1ee0b4a90>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# View histogram of all features again now with the hour feature\n",
        "train.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBXilNiJsZL5"
      },
      "source": [
        "## Step 5: Rerun the model with the same settings as before, just with more features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "oWLAUWOGsZL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35f0ff1-338d-4173-db64-80beacd84251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Level 25:autogluon.common.utils.utils:No path specified. Models will be saved in: \"AutogluonModels/ag-20220823_123411/\"\n",
            "INFO:autogluon.tabular.predictor.predictor:Presets specified: ['best_quality']\n",
            "INFO:autogluon.tabular.predictor.predictor:Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "INFO:autogluon.tabular.learner.default_learner:Beginning AutoGluon training ... Time limit = 600s\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon will save models to \"AutogluonModels/ag-20220823_123411/\"\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon Version:  0.5.2\n",
            "INFO:autogluon.tabular.learner.default_learner:Python Version:     3.7.13\n",
            "INFO:autogluon.tabular.learner.default_learner:Operating System:   Linux\n",
            "INFO:autogluon.tabular.learner.default_learner:Train Data Rows:    10886\n",
            "INFO:autogluon.tabular.learner.default_learner:Train Data Columns: 12\n",
            "INFO:autogluon.tabular.learner.default_learner:Label Column: count\n",
            "INFO:autogluon.tabular.learner.default_learner:Preprocessing data ...\n",
            "Level 25:autogluon.core.utils.utils:AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "INFO:autogluon.core.utils.utils:\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
            "Level 25:autogluon.core.utils.utils:\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "INFO:autogluon.tabular.learner.default_learner:Using Feature Generators to preprocess the data ...\n",
            "INFO:autogluon.features.generators.abstract:Fitting AutoMLPipelineFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tAvailable Memory:                    11486.5 MB\n",
            "INFO:autogluon.features.generators.abstract:\tTrain Data (Original)  Memory Usage: 1.33 MB (0.0% of available memory)\n",
            "INFO:autogluon.features.generators.abstract:\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "INFO:autogluon.features.generators.abstract:\tStage 1 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting AsTypeFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "INFO:autogluon.features.generators.abstract:\tStage 2 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting FillNaFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tStage 3 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting IdentityFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting CategoryFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tStage 4 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting DropUniqueFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tTypes of features in original data (raw dtype, special dtypes):\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('category', []) : 2 | ['season', 'weather']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', [])      : 6 | ['holiday', 'workingday', 'humidity', 'year', 'month', ...]\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('object', [])   : 1 | ['time']\n",
            "INFO:autogluon.features.generators.abstract:\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('category', [])  : 3 | ['season', 'weather', 'time']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('float', [])     : 3 | ['temp', 'atemp', 'windspeed']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', [])       : 3 | ['humidity', 'month', 'day']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', ['bool']) : 3 | ['holiday', 'workingday', 'year']\n",
            "INFO:autogluon.features.generators.abstract:\t0.2s = Fit runtime\n",
            "INFO:autogluon.features.generators.abstract:\t12 features in original data used to generate 12 features in processed data.\n",
            "INFO:autogluon.features.generators.abstract:\tTrain Data (Processed) Memory Usage: 0.59 MB (0.0% of available memory)\n",
            "INFO:autogluon.tabular.learner.default_learner:Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "Level 25:autogluon.core.trainer.abstract_trainer:AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "Level 25:autogluon.core.trainer.abstract_trainer:\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "INFO:autogluon.core.trainer.abstract_trainer:AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting 11 L1 models ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.74s of the 599.75s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-154.0311\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.05s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.1s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.44s of the 599.45s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-154.1834\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.03s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.11s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.17s of the 599.18s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-39.4525\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t36.8s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t3.04s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L1 ... Training model for up to 358.98s of the 558.99s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-39.9439\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t26.69s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t1.5s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 328.37s of the 528.38s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-42.1666\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t10.84s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.66s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L1 ... Training model for up to 316.07s of the 516.09s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.8237\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t265.76s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.41s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 46.86s of the 246.87s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-41.739\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t5.97s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.66s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 39.5s of the 239.51s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-43.336\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t49.68s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.46s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Completed 1/20 k-fold bagging repeats ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 186.51s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.2814\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.44s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting 9 L2 models ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 186.03s of the 186.01s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-39.3556\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t21.93s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.28s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBM_BAG_L2 ... Training model for up to 160.11s of the 160.09s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-39.2043\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t21.32s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.15s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 133.76s of the 133.73s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-39.4522\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t31.21s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.76s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: CatBoost_BAG_L2 ... Training model for up to 100.99s of the 100.97s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.6601\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t62.89s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.12s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 34.87s of the 34.85s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.5301\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t8.96s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.72s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 24.45s of the 24.44s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.9575\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t40.18s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.5s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Completed 1/20 k-fold bagging repeats ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -19.04s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.2443\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.34s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon training complete, total runtime = 619.42s ... Best model: \"WeightedEnsemble_L3\"\n",
            "INFO:autogluon.tabular.predictor.predictor:TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220823_123411/\")\n"
          ]
        }
      ],
      "source": [
        "predictor_new_features = TabularPredictor(label='count', eval_metric='root_mean_squared_error').fit(\n",
        "    train, presets='best_quality', time_limit=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26wO8mLwsZL6"
      },
      "outputs": [],
      "source": [
        "predictor_new_features.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8k5exFfsZL6"
      },
      "outputs": [],
      "source": [
        "# Remember to set all negative values to zero\n",
        "predictions2=predictor_new_features.predict(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = predictions2._get_numeric_data()\n",
        "\n",
        "num[num < 0] = 0"
      ],
      "metadata": {
        "id": "K-CX4F0IwNjV"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo0wOFqSxJS2",
        "outputId": "f0e420be-eb3a-47c9-a79a-7774e00367b1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14.033154\n",
              "1     4.659222\n",
              "2     3.539883\n",
              "3     3.559190\n",
              "4     3.009579\n",
              "Name: count, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_EQZm_vviZK",
        "outputId": "9b60b138-82cb-4428-dd13-e20279d190a9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6493.000000\n",
              "mean      188.487717\n",
              "std       172.267151\n",
              "min         0.000000\n",
              "25%        45.204777\n",
              "50%       146.300079\n",
              "75%       280.765686\n",
              "max       882.096863\n",
              "Name: count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx5pKWtusZL6"
      },
      "outputs": [],
      "source": [
        "# Same submitting predictions\n",
        "submission_new_features = pd.read_csv('/content/sampleSubmission.csv')\n",
        "submission_new_features['datetime']=pd.to_datetime(submission_new_features.loc[:, \"datetime\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_new_features[\"count\"] = predictions2\n",
        "submission_new_features.to_csv(\"submission_new_features.csv\", index=False)"
      ],
      "metadata": {
        "id": "t-x56I1GxOIO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "5PmMNItcsZL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5bcb69-7928-47f4-84cb-24ccdb6b5a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:00<00:00, 304kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission_new_features.csv -m \"new features\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "D0q01l8KsZL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e49732-ccbc-4895-d042-0bf4fe33be6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                     date                 description           status    publicScore  privateScore  \n",
            "---------------------------  -------------------  --------------------  --------  -----------  ------------  \n",
            "submission_new_features.csv  2022-08-23 12:54:52  new features          complete  0.44182      0.44182       \n",
            "submission.csv               2022-08-23 11:54:43  first raw submission  complete  1.80394      1.80394       \n",
            "submission.csv               2022-08-22 16:11:25  first raw submission  complete  1.77783      1.77783       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NiAv-uTsZL7"
      },
      "source": [
        "#### New Score of `0.44182 `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C0VJ_W1sZL7"
      },
      "source": [
        "## Step 6: Hyper parameter optimization\n",
        "* There are many options for hyper parameter optimization.\n",
        "* Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.\n",
        "* The hyperparameters of the models themselves that are in AutoGluon. Those need the `hyperparameter` and `hyperparameter_tune_kwargs` arguments."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters={'model': 'GBM', 'batch_size': 16, 'lr': 0.001, 'epochs': 10}"
      ],
      "metadata": {
        "id": "Wv0MlphJ1K2M"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "i2DYyz9nsZL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed0f01b-d67e-48f3-f381-4236935ed866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Level 25:autogluon.common.utils.utils:No path specified. Models will be saved in: \"AutogluonModels/ag-20220823_140630/\"\n",
            "INFO:autogluon.tabular.predictor.predictor:Presets specified: ['best_quality']\n",
            "WARNING:autogluon.tabular.predictor.predictor:Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "INFO:autogluon.tabular.predictor.predictor:Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
            "INFO:autogluon.tabular.learner.default_learner:Beginning AutoGluon training ... Time limit = 600s\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon will save models to \"AutogluonModels/ag-20220823_140630/\"\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon Version:  0.5.2\n",
            "INFO:autogluon.tabular.learner.default_learner:Python Version:     3.7.13\n",
            "INFO:autogluon.tabular.learner.default_learner:Operating System:   Linux\n",
            "INFO:autogluon.tabular.learner.default_learner:Train Data Rows:    10886\n",
            "INFO:autogluon.tabular.learner.default_learner:Train Data Columns: 12\n",
            "INFO:autogluon.tabular.learner.default_learner:Label Column: count\n",
            "INFO:autogluon.tabular.learner.default_learner:Preprocessing data ...\n",
            "Level 25:autogluon.core.utils.utils:AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "INFO:autogluon.core.utils.utils:\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
            "Level 25:autogluon.core.utils.utils:\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "INFO:autogluon.tabular.learner.default_learner:Using Feature Generators to preprocess the data ...\n",
            "INFO:autogluon.features.generators.abstract:Fitting AutoMLPipelineFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tAvailable Memory:                    11771.13 MB\n",
            "INFO:autogluon.features.generators.abstract:\tTrain Data (Original)  Memory Usage: 1.33 MB (0.0% of available memory)\n",
            "INFO:autogluon.features.generators.abstract:\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "INFO:autogluon.features.generators.abstract:\tStage 1 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting AsTypeFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "INFO:autogluon.features.generators.abstract:\tStage 2 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting FillNaFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tStage 3 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting IdentityFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting CategoryFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tStage 4 Generators:\n",
            "INFO:autogluon.features.generators.abstract:\t\tFitting DropUniqueFeatureGenerator...\n",
            "INFO:autogluon.features.generators.abstract:\tTypes of features in original data (raw dtype, special dtypes):\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('category', []) : 2 | ['season', 'weather']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', [])      : 6 | ['holiday', 'workingday', 'humidity', 'year', 'month', ...]\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('object', [])   : 1 | ['time']\n",
            "INFO:autogluon.features.generators.abstract:\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('category', [])  : 3 | ['season', 'weather', 'time']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('float', [])     : 3 | ['temp', 'atemp', 'windspeed']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', [])       : 3 | ['humidity', 'month', 'day']\n",
            "INFO:autogluon.common.features.feature_metadata:\t\t('int', ['bool']) : 3 | ['holiday', 'workingday', 'year']\n",
            "INFO:autogluon.features.generators.abstract:\t0.3s = Fit runtime\n",
            "INFO:autogluon.features.generators.abstract:\t12 features in original data used to generate 12 features in processed data.\n",
            "INFO:autogluon.features.generators.abstract:\tTrain Data (Processed) Memory Usage: 0.59 MB (0.0% of available memory)\n",
            "INFO:autogluon.tabular.learner.default_learner:Data preprocessing and feature engineering runtime = 0.43s ...\n",
            "Level 25:autogluon.core.trainer.abstract_trainer:AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "Level 25:autogluon.core.trainer.abstract_trainer:\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "INFO:autogluon.core.trainer.abstract_trainer:AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting 11 L1 models ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: KNeighborsUnif_BAG_L1 ... Tuning model for up to 4.09s of the 599.56s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused KNeighborsUnif_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: KNeighborsDist_BAG_L1 ... Tuning model for up to 4.09s of the 599.54s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused KNeighborsDist_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: LightGBMXT_BAG_L1 ... Tuning model for up to 4.09s of the 599.52s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused LightGBMXT_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 4.09s of the 599.52s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused LightGBM_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: RandomForestMSE_BAG_L1 ... Tuning model for up to 4.09s of the 599.5s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused RandomForestMSE_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 4.09s of the 599.49s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused CatBoost_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: ExtraTreesMSE_BAG_L1 ... Tuning model for up to 4.09s of the 599.48s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused ExtraTreesMSE_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: NeuralNetFastAI_BAG_L1 ... Tuning model for up to 4.09s of the 599.46s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused NeuralNetFastAI_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 180, in initialize\n",
            "    hyperparameter_tune_kwargs['scheduler'],\n",
            "KeyError: 'scheduler'\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:'scheduler'\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 4.09s of the 599.45s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused XGBoost_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 4.09s of the 599.44s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused NeuralNetTorch_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 180, in initialize\n",
            "    hyperparameter_tune_kwargs['scheduler'],\n",
            "KeyError: 'scheduler'\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:'scheduler'\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4.09s of the 599.43s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 1 child models (S1F1 - S1F1) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-37.6232\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t4.66s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.17s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 389.52s of the 589.47s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.0675\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t48.64s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t2.89s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 2/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 342.09s of the 542.04s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-39.1386\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t100.14s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t6.52s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 3/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 286.29s of the 486.24s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.9399\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t146.6s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t9.24s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 4/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 234.77s of the 434.71s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.8312\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t196.56s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t12.42s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 5/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 180.5s of the 380.44s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.8713\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t254.27s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t15.24s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 6/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 114.25s of the 314.2s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.8099\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t307.37s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t18.99s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Completed 6/20 k-fold bagging repeats ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 255.26s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-38.8099\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.01s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting 9 L2 models ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: LightGBMXT_BAG_L2 ... Tuning model for up to 3.19s of the 255.22s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused LightGBMXT_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 3.19s of the 255.21s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused LightGBM_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: RandomForestMSE_BAG_L2 ... Tuning model for up to 3.19s of the 255.19s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused RandomForestMSE_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 3.19s of the 255.18s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused CatBoost_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: ExtraTreesMSE_BAG_L2 ... Tuning model for up to 3.19s of the 255.17s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused ExtraTreesMSE_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: NeuralNetFastAI_BAG_L2 ... Tuning model for up to 3.19s of the 255.16s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused NeuralNetFastAI_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 180, in initialize\n",
            "    hyperparameter_tune_kwargs['scheduler'],\n",
            "KeyError: 'scheduler'\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:'scheduler'\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: XGBoost_BAG_L2 ... Tuning model for up to 3.19s of the 255.16s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused XGBoost_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 318, in initialize\n",
            "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial='auto', ngpus_per_trial='auto')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/scheduler_factory.py\", line 76, in scheduler_factory\n",
            "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
            "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 2}\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 3.19s of the 255.15s of remaining time.\n",
            "ERROR:autogluon.core.trainer.abstract_trainer:Warning: Exception caused NeuralNetTorch_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1385, in _train_single_full\n",
            "    **model_fit_kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 996, in hyperparameter_tune\n",
            "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/hpo/executors.py\", line 180, in initialize\n",
            "    hyperparameter_tune_kwargs['scheduler'],\n",
            "KeyError: 'scheduler'\n",
            "WARNING:autogluon.core.trainer.abstract_trainer:'scheduler'\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3.19s of the 255.14s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 1 child models (S1F1 - S1F1) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-41.6328\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t2.19s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.02s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 250.14s of the 250.13s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 7 child models (S1F2 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-41.2172\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t24.75s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.21s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 2/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 224.58s of the 224.57s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.8213\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t49.71s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.44s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 3/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 196.05s of the 196.03s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.6208\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t74.12s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.64s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 4/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 168.21s of the 168.2s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.643\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t99.67s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.86s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 5/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 138.96s of the 138.95s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.5679\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t124.78s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t1.12s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 6/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 110.13s of the 110.12s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.5463\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t149.43s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t1.37s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 7/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 81.64s of the 81.63s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.5702\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t174.45s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t1.6s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Repeating k-fold bagging: 8/20\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 52.42s of the 52.41s of remaining time.\n",
            "INFO:autogluon.core.models.ensemble.bagged_ensemble_model:\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.5486\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t199.73s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t1.84s\t = Validation runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Completed 8/20 k-fold bagging repeats ...\n",
            "INFO:autogluon.core.trainer.abstract_trainer:Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 23.22s of remaining time.\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t-40.5486\t = Validation score   (-root_mean_squared_error)\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.01s\t = Training   runtime\n",
            "INFO:autogluon.core.trainer.abstract_trainer:\t0.0s\t = Validation runtime\n",
            "INFO:autogluon.tabular.learner.default_learner:AutoGluon training complete, total runtime = 576.84s ... Best model: \"WeightedEnsemble_L2\"\n",
            "INFO:autogluon.tabular.predictor.predictor:TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220823_140630/\")\n"
          ]
        }
      ],
      "source": [
        "predictor_new_hpo = TabularPredictor(label='count', eval_metric='root_mean_squared_error').fit(\n",
        "    train, presets='best_quality', time_limit=600,hyperparameters='default' , hyperparameter_tune_kwargs={'num_trials': 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ayp0KkWYsZL7"
      },
      "outputs": [],
      "source": [
        "predictor_new_hpo.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor3=predictor_new_hpo.predict(test)\n",
        "predictor3.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azFf_0A4Cgus",
        "outputId": "f94ea800-2c41-4872-ef4b-d78a3de76d8d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6493.000000\n",
              "mean      191.968582\n",
              "std       172.601654\n",
              "min        -6.691428\n",
              "25%        50.275204\n",
              "50%       152.152084\n",
              "75%       286.702026\n",
              "max       889.206482\n",
              "Name: count, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "r79X160PsZL7"
      },
      "outputs": [],
      "source": [
        "# Remember to set all negative values to zero\n",
        "num = predictor3._get_numeric_data()\n",
        "\n",
        "num[num < 0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "bB9TeXeusZL7"
      },
      "outputs": [],
      "source": [
        "# Same submitting predictions\n",
        "submission_new_hpo = pd.read_csv('/content/sampleSubmission.csv')\n",
        "submission_new_hpo['datetime']=pd.to_datetime(submission_new_hpo.loc[:, \"datetime\"])\n",
        "\n",
        "submission_new_hpo[\"count\"] = predictor3\n",
        "submission_new_hpo.to_csv(\"submission_new_hpo.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "66S_QEy3sZL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd5b2a5-036e-4931-f81b-2a4ad6c7f0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 188k/188k [00:00<00:00, 396kB/s]\n",
            "Successfully submitted to Bike Sharing Demand"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c bike-sharing-demand -f submission_new_hpo.csv -m \"new features with hyperparameters\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "fM3Odxd-sZL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0378d7-501b-465b-826f-254776446ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                     date                 description                        status    publicScore  privateScore  \n",
            "---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  \n",
            "submission_new_hpo.csv       2022-08-23 14:19:29  new features with hyperparameters  complete  0.53131      0.53131       \n",
            "submission_new_features.csv  2022-08-23 12:54:52  new features                       complete  0.44182      0.44182       \n",
            "submission.csv               2022-08-23 11:54:43  first raw submission               complete  1.80394      1.80394       \n",
            "submission.csv               2022-08-22 16:11:25  first raw submission               complete  1.77783      1.77783       \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4r7fQJJsZL8"
      },
      "source": [
        "#### New Score of `0.53131      `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX9tE7XSsZL8"
      },
      "source": [
        "## Step 7: Write a Report\n",
        "### Refer to the markdown file for the full report\n",
        "### Creating plots and table for report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "GXMGaV1AsZL8"
      },
      "outputs": [],
      "source": [
        "# Taking the top model score from each training run and creating a line plot to show improvement\n",
        "# You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)\n",
        "fig = pd.DataFrame(\n",
        "    {\n",
        "        \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "        \"score\": [?, ?, ?]\n",
        "    }\n",
        ").plot(x=\"model\", y=\"score\", figsize=(8, 6)).get_figure()\n",
        "fig.savefig('model_train_score.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRAXXjs9sZL9"
      },
      "outputs": [],
      "source": [
        "# Take the 3 kaggle scores and creating a line plot to show improvement\n",
        "fig = pd.DataFrame(\n",
        "    {\n",
        "        \"test_eval\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "        \"score\": [?, ?, ?]\n",
        "    }\n",
        ").plot(x=\"test_eval\", y=\"score\", figsize=(8, 6)).get_figure()\n",
        "fig.savefig('model_test_score.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpVxtS3usZL9"
      },
      "source": [
        "### Hyperparameter table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sYUG4uGsZL9"
      },
      "outputs": [],
      "source": [
        "# The 3 hyperparameters we tuned with the kaggle score as the result\n",
        "pd.DataFrame({\n",
        "    \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
        "    \"hpo1\": [?, ?, ?],\n",
        "    \"hpo2\": [?, ?, ?],\n",
        "    \"hpo3\": [?, ?, ?],\n",
        "    \"score\": [?, ?, ?]\n",
        "})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "name": "project1Autogluon].ipynb",
      "collapsed_sections": [
        "w2VfJbDWsZL1",
        "ipekDzVlsZL1",
        "MGnqSpMysZL1",
        "jmnwzMjKsZL2",
        "15WNqojCsZL3",
        "PjER-eF0sZL4",
        "2NiAv-uTsZL7",
        "T4r7fQJJsZL8",
        "xpVxtS3usZL9"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}